# -*- coding: utf-8 -*-
"""RandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yD_T7EPUgCio3XOriS9BJA0BZmAbY9HL
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
from keras.layers import *
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from keras.callbacks import EarlyStopping
from numpy import *
from pandas import *
from sklearn.metrics import *
from sklearn.ensemble import RandomForestRegressor
from math import sqrt

from google.colab import drive
drive.mount('/content/drive')

#if you want to predict variables for Up reserve energy set energy_type='Up'
#if you want to predict variables for Down reserve energy set energy_type='Down'
energy_type='Up'



if energy_type==True:
  df= pd.read_excel('/content/drive/MyDrive/BE/BE_names.xlsx')
else:
  df= pd.read_excel('/content/drive/MyDrive/BE/Actual_Units_Down.xlsx')
Date= pd.read_excel('/content/drive/MyDrive/BE/DateDim.xlsx')

df

entityname=df.names.values
entityname1 = entityname[32:33]
for i in entityname:
  vars()[i] = pd.read_excel('/content/drive/MyDrive/BE/BE_'+str(energy_type)+'_New_New/%s.xlsx' % i)
  vars()[i] = vars()[i].set_index('Date')
  vars()[i] = vars()[i].fillna(0)
  print(i)

Date['Day'] = pd.to_datetime(Date['Day'])
Date = Date.set_index('Day')
Date = Date.loc['2021-02-13':'2021-07-14']

date1 = Date.loc[:, 'SinWeekDay':'CosHour']

scl = MinMaxScaler()



column_name = []
for k in range(0, 336):
  column_name.append('predicted')
  column_name.append('real')

def quantity_values(entity, max_steps):
  quantity = entity.loc[:, 'Step1Quantity':'Step'+str(max_steps)+'Quantity']
  for i in range(1, max_steps+1):
    
    column_values = quantity['Step'+str(i)+'Quantity'].values
    stepval = 'Step'+str(i)+'Val'
    vars()[stepval] =  np.unique(column_values)
    vars()[stepval] = pd.DataFrame(vars()[stepval])
    if i ==1:
      val = vars()[stepval].copy()
    else:
      val = pd.concat([val, vars()[stepval]], axis=1)
  
  val= val.fillna(0)
  return val

def classification(value, x, max_list, max_quantity):
  clas = []
  dif=[]
  for i in range(0, len(value)):
    dif.append(abs(x[0]-value.iat[i,0]))
  min_dif = min(dif)
  clas.append(value.iat[dif.index(min(dif)), 0])
  step = 0
  for j in range(1, len(x)):
    dif=[]
    if clas[j-1]<max_list[j-1] or clas[j-1]!=0:
      for i in range(0, len(value)):
        dif.append(abs(x[j]-value.iat[i,j]))
      if min(dif)<min_dif:
        clas.append(value.iat[dif.index(min(dif)), j])
        min_dif = min(dif)
        step = j
      else:
        if clas[j-1] == max_list[j-1]:
          clas.append(0)
        else:
          clas.append(value.iat[dif.index(min(dif)), j])
    else:
      clas.append(0)
  if sum(clas)<max_quantity[0]:
    clas[step] += max_quantity[0]-sum(clas)
  clas = np.array(clas)
  return clas

def split_sequences(data, lookback, lookforward, max_steps):
	X, y = list(), list()
	for i in range(len(data)-lookback):
		end_ix = i + lookback
		out_end_ix = end_ix + lookforward
		if out_end_ix > len(data):
			break
		seq_x, seq_y = data[i:end_ix, 0:data.shape[1]], data[end_ix:out_end_ix, 0:max_steps]
		X.append(seq_x)
		y.append(seq_y)
	return np.array(X), np.array(y)

def accuracy_score_manual(pred, real):
  k=0
  for i in range(0, len(pred)):
    if pred.iat[i] == real.iat[i]:
      k+=1
  return k*100/len(pred)

def classify_steps(max_steps, steps):
  k = pd.DataFrame(index=np.arange(len(steps)), columns=np.arange(max_steps))
  for i in range(0, len(steps)):

    for j in range(1, max_steps+1):
      if steps.iat[i] == j:
        k.iat[i,j-1] = 1
  k = k.fillna(0)
  return k

def percentage_error(actual, predicted):
  res = list()
  for j in range(actual.shape[0]):
    if actual[j] != 0:
      res.append((actual[j] - predicted[j]) / actual[j])
    elif np.mean(actual)!=0:
      res.append(predicted[j] / np.mean(actual))
    else: 
      res.append(0)
  return res

error_index = entityname.copy()
error_index = np.append(error_index, 'mean')

error_name = []
for k in range(1,11):
  error_name.append('MAE')
  error_name.append('RMSE')
error_name.append('Accuracy')

g=0
tot_error = pd.DataFrame(index=np.arange(len(error_index)), columns=np.arange(21))
tot_pred = 0
weeks_of_pred = 7
    
for i in entityname1:
  stop_val=0
  entity = vars()[i]
  entity = entity.loc['2021-02-13':'2021-07-14']
  variable= entity.loc[:, 'VariableCost']
  availability = entity.loc[:, 'Availability']
  min_step = min(entity.NumOfSteps)
  max_steps = max(entity.NumOfSteps)
  entity1 = entity.iloc[:, 3:3+max_steps]
  max_list = entity1.max(axis=0).values
  min_list = entity1.min(axis=0).values

  if max_steps > 0:
    tot_pred += 1
    final_mae = pd.DataFrame(index=np.arange(weeks_of_pred+1), columns=np.arange(2+2*max_steps))
    for t in range(0, 7):
      a = pd.read_excel('/content/drive/MyDrive/BE/BE_'+str(energy_type)+'_New/Classification/predictions/'+str(i)+'at'+str(t)+'day.xlsx')
      a = a.set_index('Date')
     
       

      

      prediction = pd.DataFrame(index=np.arange(a.shape[0]), columns=np.arange(max_steps))
      real_val = pd.DataFrame(index=np.arange(a.shape[0]), columns=np.arange(max_steps))
      for z in range(0, max_steps):
        dataset2 = entity.iloc[:len(entity)-336-(6-t)*48, :]
        dataset3 = entity.iloc[len(entity)-336-(6-t)*48:(len(entity)-(6-t)*48), :]
        steps1  = dataset2.NumOfSteps
        steps2 = a.Predicted
        dataset2 = entity.iloc[:len(entity)-336-(6-t)*48, 3+z:4+z]
        dataset3 = entity.iloc[len(entity)-336-(6-t)*48:(len(entity)-(6-t)*48), 3+z:4+z]
        dataset_f1  = pd.concat([dataset2, dataset3])
        dataset_f2 = pd.concat([steps1, steps2])

        dataset_f3 = pd.concat([dataset_f1, dataset_f2], axis=1)
        #dataset_f3 = dataset_f3.rename(columns = {dataset_f3.columns[1]:'NumOfSteps'})
        
        dataset_final = dataset_f3
        
        cl2 = dataset_final.values.reshape(dataset_final.shape[0],2)
        
        #cl2 = scl.fit_transform(cl)
        train_x = cl2[:int(len(dataset_final)*0.7), 1]
        train_y = cl2[:int(len(dataset_final)*0.7), 0]
        test_x = cl2[int(len(dataset_final)*0.7):len(dataset_final)-336, 1]
        test_y = cl2[int(len(dataset_final)*0.7):len(dataset_final)-336, 0]
        pred_x = cl2[len(dataset_final)-336:, 1]
        pred_y = cl2[len(dataset_final)-336:, 0]
        train_x = train_x.reshape(len(train_x), 1)
        train_y = train_y.reshape(len(train_y), 1)
        test_x = test_x.reshape(len(test_x), 1)
        test_y = test_x.reshape(len(test_y),1)
        pred_x = pred_x.reshape(len(pred_x),1)
        pred_y = pred_y.reshape(len(pred_y),1)
        
        train_y = np.ravel(train_y)
        pred_y = np.ravel(pred_y)

        regressor = RandomForestRegressor(n_estimators = 500, random_state = 0)
        regressor.fit(train_x, train_y)
        
        p = regressor.predict(pred_x)
        
        for k in range(0, len(p)):
          prediction.iat[k,z] = p[k]
          real_val.iat[k,z] = float(pred_y[k])
      
      
      
      
      
      table2 = pd.DataFrame(index=np.arange(prediction.shape[0]), columns=np.arange(2*max_steps+2))

      
      
      for k in range(0, prediction.shape[0]):
        for j in range(0,prediction.shape[1]):
          table2.iat[k,2*j] = prediction.iat[k,j]
          table2.iat[k, 2*j+1] = real_val.iat[k,j]
        table2.iat[k, 2*max_steps] = a.iat[k,0]
        table2.iat[k, 2*max_steps+1] = a.iat[k,1]

        
      name=[]
      for j in range(0, max_steps):
        name.append('Step'+str(j+1)+'Predicted')
        name.append('Step'+str(j+1)+'Real')
      name.append('NumOfSteps_pred')
      name.append('NumOfSteps_real')

      table2.columns = name
      table2.index = a.index
      table2 = table2.fillna(0)
      table2.to_excel('/content/drive/MyDrive/BE/BE_'+str(energy_type)+'_New/GRU-RF/Quantity_pred/predictions/'+str(i)+'at'+str(t)+'day.xlsx')
      fig = plt
      table2['Step1Real'].plot(figsize=(30,18), fontsize=30)
      table2['Step1Predicted'].plot(figsize=(30,18), fontsize=30)
      plt.title(''+str(i)+' Step1 Quantity', fontsize=30)
      plt.xlabel("Date", fontsize=30)
      plt.ylabel("Quantity", fontsize=30)
      plt.xticks(fontsize=30)
      plt.yticks(fontsize=30)
      plt.legend(prop={'size':30})
      #plt.show()
      fig.savefig('/content/drive/MyDrive/BE/BE_'+str(energy_type)+'_New/GRU-RF/Quantity_pred/diagrams/'+str(i)+ ' prediction at '+str(t)+'day.png')
      if t==6:
        fig.savefig('/content/drive/MyDrive/BE/BE_'+str(energy_type)+'_New/GRU-RF/Quantity_pred/diagram_final/'+str(i)+ '.png')
      plt.close()

      col = 1    
      index_list = a.index.tolist()
      first_day = index_list[0].day
      first_day_month = index_list[0].month
      last_day = index_list[len(index_list)-1].day
      last_day_month = index_list[len(index_list)-1].month
      date = '{}/{}-{}/{}'.format(first_day, first_day_month, last_day, last_day_month)
      
      
      #mae.iat[t,0] = date
      #mae.iat[t,1] = accuracy_score_manual(a.iloc[:, 0], a.iloc[:, 1])
      final_mae.iat[t,0] = date
      

      for k in range(0, max_steps):

        final_mae.iat[t, 2*k+1] = mean_absolute_error(table2.iloc[:,2*k:2*k+1], table2.iloc[:, 2*k+1:2*k+2])
        final_mae.iat[t, 2*k+2] = sqrt(mean_squared_error(table2.iloc[:,2*k:2*k+1], table2.iloc[:, 2*k+1:2*k+2]))
      final_mae.iat[t, 2*max_steps+1] = accuracy_score_manual(a.iloc[:, 0], a.iloc[:, 1])
          
    mae_col_name = []
    mae_col_name.append('Date')
    for j in range(1, max_steps+1):
      mae_col_name.append('MAE')
      mae_col_name.append('RMSE')
    mae_col_name.append('Accuracy')
    #mae.iat[weeks_of_pred, 0] = 'mean accuracy'  
    final_mae.iat[weeks_of_pred, 0] = 'mean error'      
    #mae.columns = ['Date', 'Accuracy']
    #mae =  mae.set_index('Date')
    #accuracy_sum = mae.sum().tolist()
    #mae.iat[weeks_of_pred, 0] = accuracy_sum[0]/weeks_of_pred
    #tot_accuracy.iat[g, 0] =accuracy_sum[0]/(weeks_of_pred)
    #mae.to_excel('/content/drive/MyDrive/BE/BE_Up_New/GRU-RF/Classification/accuracy/'+str(i)+'.xlsx')
    final_mae.columns = mae_col_name
    final_mae =  final_mae.set_index('Date')
    final_mae_sum = final_mae.sum().tolist()
    for k in range(0, len(final_mae.columns)-1):
        final_mae.iat[weeks_of_pred, k] = final_mae_sum[k]/(weeks_of_pred)
        tot_error.iat[g, k] = final_mae_sum[k]/(weeks_of_pred)
    tot_error.iat[g, 20] =final_mae_sum[len(final_mae.columns)-1]/(weeks_of_pred)
    final_mae.iat[weeks_of_pred, len(final_mae.columns)-1] = final_mae_sum[len(final_mae.columns)-1]/(weeks_of_pred)
    final_mae.to_excel('/content/drive/MyDrive/BE/BE_'+str(energy_type)+'_New/GRU-RF/Quantity_pred/error/'+str(i)+'.xlsx')
    print(g, i)
    g+=1

tot_mae_sum = tot_error.sum().tolist()
for k in range(len(tot_error.columns)):
  tot_error.iat[len(tot_error)-1,k] = tot_mae_sum[k]/tot_pred


tot_error.columns = error_name
tot_error.index = error_index
tot_error.to_excel('/content/drive/MyDrive/BE/BE_'+str(energy_type)+'_New/GRU-RF/Quantity_pred/TOT-ACCURACY 4layers 500batch.xlsx')



